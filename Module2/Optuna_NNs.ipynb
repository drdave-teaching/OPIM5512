{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e56dcc1",
   "metadata": {},
   "source": [
    "# Optuna and NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\dww05002\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dww05002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dww05002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dww05002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from optuna) (4.67.1)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\dww05002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dww05002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "   ---------------------------------------- 0.0/400.9 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 184.3/400.9 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 400.9/400.9 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "   ---------------------------------------- 0.0/247.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 247.4/247.4 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.1/2.1 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 33.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 27.1 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.8/158.8 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 299.1/299.1 kB 18.1 MB/s eta 0:00:00\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Installing collected packages: PyYAML, MarkupSafe, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 MarkupSafe-3.0.3 PyYAML-6.0.3 alembic-1.16.5 colorlog-6.9.0 greenlet-3.2.4 optuna-4.5.0 sqlalchemy-2.0.43\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 11:52:42,885] A new study created in memory with name: no-name-5df68409-07c8-4623-aee7-0597f43f0e2b\n",
      "Best trial: 0. Best value: 0.354051:   2%|▎         | 1/40 [01:38<1:04:08, 98.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 11:54:21,560] Trial 0 finished with value: 0.35405134313968545 and parameters: {'n_layers': 2, 'n_units_l1': 512, 'n_units_l2': 384, 'activation': 'relu', 'alpha': 6.025215736203862e-06, 'learning_rate_init': 0.00014936568554617635, 'batch_size': 512}. Best is trial 0 with value: 0.35405134313968545.\n"
     ]
    }
   ],
   "source": [
    "# Optuna + MLPRegressor on California Housing\n",
    "# - 80/10/10 split (same as before)\n",
    "# - StandardScaler fit on train; applied to val/test\n",
    "# - Optuna tunes MLP hyperparams by minimizing validation MAE\n",
    "# - Retrain best model on train+val; evaluate on test (R², MAE, MAPE)\n",
    "# - Scatter plot (pred vs actual) for test\n",
    "\n",
    "%pip install optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # MLP may emit ConvergenceWarning\n",
    "\n",
    "import optuna\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 1) Load data\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.frame.drop(columns=[\"MedHouseVal\"])\n",
    "y = data.frame[\"MedHouseVal\"]\n",
    "\n",
    "# 2) 80/10/10 split (fixed random_state for reproducibility)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 3) Scale features with train-only statistics\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Define Optuna objective: minimize validation MAE\n",
    "def objective(trial):\n",
    "    # Architecture: 1–3 layers, 32–512 units each\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    hidden_sizes = []\n",
    "    for i in range(n_layers):\n",
    "        units = trial.suggest_int(f\"n_units_l{i+1}\", 32, 512, step=32)\n",
    "        hidden_sizes.append(units)\n",
    "    hidden_sizes = tuple(hidden_sizes)\n",
    "\n",
    "    params = {\n",
    "        \"hidden_layer_sizes\": hidden_sizes,\n",
    "        \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        \"solver\": \"adam\",  # stable choice for MLP\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1e-1, log=True),  # L2\n",
    "        \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512]),\n",
    "        \"max_iter\": 1000,                # give it room to converge\n",
    "        \"early_stopping\": False,         # we use external val set; avoid internal split\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"shuffle\": True,\n",
    "    }\n",
    "\n",
    "    model = MLPRegressor(**params)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    y_val_pred = model.predict(X_val_s)\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    return val_mae\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "print(f\"  Validation MAE: {study.best_value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"    {k}: {v}\")\n",
    "\n",
    "# 5) Retrain best model on TRAIN+VAL, evaluate on TEST\n",
    "best = study.best_params\n",
    "# Rebuild hidden_layer_sizes from params\n",
    "n_layers = best[\"n_layers\"]\n",
    "hidden_sizes = tuple(best[f\"n_units_l{i+1}\"] for i in range(n_layers))\n",
    "\n",
    "final_params = {\n",
    "    \"hidden_layer_sizes\": hidden_sizes,\n",
    "    \"activation\": best[\"activation\"],\n",
    "    \"solver\": \"adam\",\n",
    "    \"alpha\": best[\"alpha\"],\n",
    "    \"learning_rate_init\": best[\"learning_rate_init\"],\n",
    "    \"batch_size\": best[\"batch_size\"],\n",
    "    \"max_iter\": 2000,       # a bit more room to fully fit\n",
    "    \"early_stopping\": False,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "\n",
    "# Combine train+val\n",
    "X_trval = np.vstack([X_train_s, X_val_s])\n",
    "y_trval = np.concatenate([y_train.values, y_val.values])\n",
    "\n",
    "final_model = MLPRegressor(**final_params)\n",
    "final_model.fit(X_trval, y_trval)\n",
    "\n",
    "# Metrics helper\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# Evaluate on all splits for completeness\n",
    "y_pred_train = final_model.predict(X_train_s)\n",
    "y_pred_val   = final_model.predict(X_val_s)\n",
    "y_pred_test  = final_model.predict(X_test_s)\n",
    "\n",
    "rows = [\n",
    "    {\"split\": \"train\", **metrics(y_train, y_pred_train)},\n",
    "    {\"split\": \"val\",   **metrics(y_val,   y_pred_val)},\n",
    "    {\"split\": \"test\",  **metrics(y_test,  y_pred_test)},\n",
    "]\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "print(\"\\n=== Final Metrics (best params retrained on train+val) ===\")\n",
    "print(metrics_df.round(4).to_string(index=False))\n",
    "\n",
    "# 6) Scatter plot (Test)\n",
    "def scatter_with_reference(y_true, y_pred, title):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
    "    lo = min(np.min(y_true), np.min(y_pred))\n",
    "    hi = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([lo, hi], [lo, hi], linewidth=1)\n",
    "    plt.xlabel(\"Actual MedHouseVal\")\n",
    "    plt.ylabel(\"Predicted MedHouseVal\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "scatter_with_reference(y_test, y_pred_test, \"Predicted vs Actual — Test (Optuna-tuned MLP)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
