{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teV48wO269KY"
      },
      "source": [
        "# Advanced Pipelines with Grid Search (classification)\n",
        "**OPIM 5512: Data Science Using Python - University of Connecticut**\n",
        "\n",
        "---------------------------------\n",
        "This is where the real magic happens! With so many models, we won't make boxplots of the output (we will fit HUNDREDS or THOUSANDS of models). We rely on a grid search and simply retrieve the model with the best average error metric. Although we are focusing on classification in this notebook, you can apply the same logic and wisdom to regression problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QorkuTCP9A3e"
      },
      "source": [
        "## Load Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjynxh0A9DMW"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# classification spot check models!\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# more advanced ensemble models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMfmhCcuegSx"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSWrpXepYacQ",
        "outputId": "b9c36a19-58c6-4003-a707-79fb8f133d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UwCOmgdOwvpMd58lVlwqUL3w1IRaYJa-\n",
            "To: /content/breastcancer.csv\n",
            "100% 125k/125k [00:00<00:00, 48.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# let's use gdown to get the data instead of mounting the drive\n",
        "# https://drive.google.com/file/d/1UwCOmgdOwvpMd58lVlwqUL3w1IRaYJa-/view?usp=sharing\n",
        "!gdown 1UwCOmgdOwvpMd58lVlwqUL3w1IRaYJa-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "_OJYyxKxdsCn",
        "outputId": "3354a493-f33a-4667-8be4-7665631a45dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-18bccdbf-d379-41c3-8994-45835027124f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18bccdbf-d379-41c3-8994-45835027124f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18bccdbf-d379-41c3-8994-45835027124f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18bccdbf-d379-41c3-8994-45835027124f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('breastcancer.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emfxK4sIe4Hw"
      },
      "source": [
        "The target variable will be `diagnosis`. Let's drop that last unnamed column while we are here. And since `id` doesn't have predictive power, let's drop that too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S53avZle8lp",
        "outputId": "9f941926-3f36-4460-84e6-ff075b4173da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
              "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
              "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
              "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
              "       'symmetry_worst', 'fractal_dimension_worst'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop('Unnamed: 32', axis=1, inplace=True)\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "df.columns # voila - it's gone!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx8KNYtvfOAY",
        "outputId": "5a0fcb22-508e-47c0-b8c3-37bf4b6e4dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    object \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info() # check for any missing values - all looks good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxEolENSfTZw"
      },
      "source": [
        "If you look at the unique values in the `diagnosis`, we see that these are... **M** for malignant and **B** for benign.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAD87VWZfeBo",
        "outputId": "6538c89c-9e8c-44f3-9255-1195b79f2ee3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'M': 212, 'B': 357})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(df['diagnosis'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlmniUShfnVg"
      },
      "source": [
        "Our data is imbalanced, and we will ignore this for now - we can use SMOTE later on with an imblearn Pipeline (different than an sklearn pipeline - be careful!) So"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY30g-TAf8JI"
      },
      "source": [
        "So that we don't have to deal with problems in a logistic regression, let's use `LabelEncoder()` from `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3kx7GgGgC1x",
        "outputId": "53a3048d-51d9-4fd4-c653-b1844ad2e6c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({1: 212, 0: 357})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()\n",
        "df['diagnosis'] = LE.fit_transform(df['diagnosis'])\n",
        "Counter(df['diagnosis'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35al3MA9g4dZ"
      },
      "source": [
        "As you can see, B is 0 and M is 1. You could use SMOTE now before all of your pipelines (if you wanted to use it for everything). But for now, we simply ignore the class balance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTgkahVeA9z8"
      },
      "source": [
        "# Prepare Data for Modeling (Split, CV, error metrics)\n",
        "At this point you are ready to:\n",
        "* Split into X and y\n",
        "* Make a train and test partition\n",
        "* Leverage 10-fold cross-validation\n",
        "* Add a seed for reproducability\n",
        "* Make a list of all of the models you are interested in evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2ZeaNA6zxRb"
      },
      "outputs": [],
      "source": [
        "# Split-out validation df\n",
        "X = df.drop('diagnosis', axis=1) #covariates - just drop the target!\n",
        "y = df['diagnosis'] #target variable\n",
        "validation_size = 0.20\n",
        "seed = 123 # so you will split the same way and evaluate the SAME dataset\n",
        "\n",
        "# split!\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=validation_size,\n",
        "                                                    random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwssq4G29H27"
      },
      "source": [
        "## Build Pipeline\n",
        "* [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "* [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
        "* [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "* [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
        "* [GBM](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
        "* [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "* [Extra Trees ](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)\n",
        "\n",
        "All of the hyperparameters that you see below came from the documentation. Of course you could include PCA or polynomial features as pre-processing here..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urnajeag9JjA"
      },
      "outputs": [],
      "source": [
        "# Construct some pipelines\n",
        "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', LogisticRegression(random_state=42))])\n",
        "\n",
        "pipe_knn = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', KNeighborsClassifier())])\n",
        "\n",
        "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', DecisionTreeClassifier(random_state=42))])\n",
        "\n",
        "pipe_ada = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', AdaBoostClassifier(random_state=42))])\n",
        "\n",
        "pipe_gb = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', GradientBoostingClassifier(random_state=42))])\n",
        "\n",
        "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', RandomForestClassifier(random_state=42))])\n",
        "\n",
        "pipe_et = Pipeline([('scl', StandardScaler()),\n",
        "\t\t\t('clf', ExtraTreesClassifier(random_state=42))])\n",
        "\n",
        "# and remember, for now these are just boring vanilla defaults... the grid is coming!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02P0w9zE_jLk"
      },
      "source": [
        "## Define your Parameters for Grid Search\n",
        "\n",
        "Note the clf - this is an artifact of the pipeline code we just wrote."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alqXt7eu_llU"
      },
      "outputs": [],
      "source": [
        "# Set grid search params\n",
        "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
        "                  'clf__C': [1, 10],\n",
        "                  'clf__solver': ['liblinear'],\n",
        "                   'clf__max_iter': [1000000]}]\n",
        "\n",
        "grid_params_knn = [{'clf__n_neighbors': [1, 3, 5, 10, 50]}]\n",
        "\n",
        "grid_params_dt = [{'clf__criterion': ['gini', 'entropy'],\n",
        "                  'clf__min_samples_leaf': [5, 10, 20, 25],\n",
        "                  'clf__max_depth': [3, 5, 10, 15, 20],\n",
        "                  'clf__min_samples_split': [5, 10, 20, 25]}]\n",
        "\n",
        "grid_params_ada = [{'clf__n_estimators': [3, 5, 10, 15, 20],\n",
        "\t\t                'clf__learning_rate': [0.001, 0.01]}]\n",
        "\n",
        "grid_params_gb = [{'clf__n_estimators': [3, 5, 10, 15, 20],\n",
        "                'clf__learning_rate': [0.001, 0.01],\n",
        "                'clf__loss': ['deviance', 'exponential']}]\n",
        "\n",
        "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
        "                  'clf__min_samples_leaf': [5, 10, 20, 25],\n",
        "                  'clf__max_depth': [3, 5, 10, 15, 20],\n",
        "                  'clf__min_samples_split': [5, 10, 20, 25],\n",
        "                  'clf__n_estimators': [30, 50, 100, 200, 500]}]\n",
        "\n",
        "grid_params_et = [{'clf__criterion': ['gini', 'entropy'],\n",
        "                  'clf__min_samples_leaf': [5, 10, 20, 25],\n",
        "                  'clf__max_depth': [3, 5, 10, 15, 20],\n",
        "                  'clf__min_samples_split': [5, 10, 20, 25],\n",
        "                  'clf__n_estimators': [30, 50, 100, 200, 500]}]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWZdck99Oue"
      },
      "source": [
        "## Define your Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcOEx0du_rPj"
      },
      "outputs": [],
      "source": [
        "# Construct grid searches\n",
        "\n",
        "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
        "    param_grid=grid_params_lr,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_knn = GridSearchCV(estimator=pipe_knn,\n",
        "    param_grid=grid_params_knn,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_dt = GridSearchCV(estimator=pipe_dt,\n",
        "    param_grid=grid_params_dt,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_ada = GridSearchCV(estimator=pipe_ada,\n",
        "    param_grid=grid_params_ada,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_gb = GridSearchCV(estimator=pipe_gb,\n",
        "    param_grid=grid_params_gb,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
        "    param_grid=grid_params_rf,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "gs_et = GridSearchCV(estimator=pipe_et,\n",
        "    param_grid=grid_params_et,\n",
        "    scoring='accuracy',\n",
        "    cv=10)\n",
        "\n",
        "# List of pipelines for ease of iteration\n",
        "grids = [gs_lr, gs_knn, gs_dt, gs_ada, gs_gb, gs_rf, gs_et]\n",
        "\n",
        "# Dictionary of pipelines and classifier types for ease of reference\n",
        "grid_dict = {0: 'Logistic Regression',\n",
        "             1: 'KNN',\n",
        "             2: 'DTC',\n",
        "             3: 'ADA',\n",
        "             4: 'GBC',\n",
        "             5: 'RFC',\n",
        "             6: 'ET'}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZv1CrKU_wVC"
      },
      "source": [
        "## Run it! Find the best model\n",
        "Go get some coffee - this will take a minute!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4ZI90ft62Zi",
        "outputId": "9d92f7bb-3cad-4dbe-c31f-3e1dc18bd523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing model optimizations...\n",
            "\n",
            "Estimator: Logistic Regression\n",
            "Best params: {'clf__C': 1, 'clf__max_iter': 1000000, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
            "Best training accuracy: 0.978\n",
            "Test set accuracy score for best params: 0.991 \n",
            "\n",
            "Estimator: KNN\n",
            "Best params: {'clf__n_neighbors': 5}\n",
            "Best training accuracy: 0.956\n",
            "Test set accuracy score for best params: 0.982 \n",
            "\n",
            "Estimator: DTC\n",
            "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5}\n",
            "Best training accuracy: 0.947\n",
            "Test set accuracy score for best params: 0.965 \n",
            "\n",
            "Estimator: ADA\n",
            "Best params: {'clf__learning_rate': 0.01, 'clf__n_estimators': 10}\n",
            "Best training accuracy: 0.901\n",
            "Test set accuracy score for best params: 0.930 \n",
            "\n",
            "Estimator: GBC\n",
            "Best params: {'clf__learning_rate': 0.001, 'clf__loss': 'deviance', 'clf__n_estimators': 3}\n",
            "Best training accuracy: 0.624\n",
            "Test set accuracy score for best params: 0.640 \n",
            "\n",
            "Estimator: RFC\n",
            "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 100}\n",
            "Best training accuracy: 0.956\n",
            "Test set accuracy score for best params: 0.991 \n",
            "\n",
            "Estimator: ET\n",
            "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 15, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5, 'clf__n_estimators': 30}\n",
            "Best training accuracy: 0.952\n",
            "Test set accuracy score for best params: 0.965 \n",
            "\n",
            "Classifier with best test set accuracy: Logistic Regression\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Fit the grid search objects\n",
        "print('Performing model optimizations...')\n",
        "best_acc = 0.0\n",
        "best_clf = 0\n",
        "best_gs = ''\n",
        "for idx, gs in enumerate(grids):\n",
        "\tprint('\\nEstimator: %s' % grid_dict[idx])\n",
        "\t# Fit grid search\n",
        "\tgs.fit(X_train, y_train)\n",
        "\t# Best params\n",
        "\tprint('Best params: %s' % gs.best_params_)\n",
        "\t# Best training data accuracy\n",
        "\tprint('Best training accuracy: %.3f' % gs.best_score_)\n",
        "\t# Predict on test data with best params\n",
        "\ty_pred = gs.predict(X_test)\n",
        "\t# Test data accuracy of model with best params\n",
        "\tprint('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
        "\t# Track best (highest test accuracy) model\n",
        "\tif accuracy_score(y_test, y_pred) > best_acc:\n",
        "\t\tbest_acc = accuracy_score(y_test, y_pred)\n",
        "\t\tbest_gs = gs\n",
        "\t\tbest_clf = idx\n",
        "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhu0Q7F4rUL4"
      },
      "source": [
        "**On Your Own:** try to add a few more models or go back and try to get the GBC to fit better - probably can do better than this!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}