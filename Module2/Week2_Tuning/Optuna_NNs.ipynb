{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f638ece",
   "metadata": {},
   "source": [
    "# üß™ Optuna + Small MLPs: What to Tweak & How It Works (High-Level)\n",
    "\n",
    "## What this notebook does\n",
    "- Splits **California Housing** into **80/10/10** (train/val/test).\n",
    "- Standardizes features with **train-only** stats.\n",
    "- Uses **Optuna** to **minimize validation MAE** by tuning a *small* `MLPRegressor` (‚â§20 units/layer) **with early stopping**.\n",
    "- Retrains the best configuration on **train+val**, evaluates on **test**, and saves useful artifacts (metrics, plots, CSV logs, pickled model/scaler).\n",
    "\n",
    "Artifacts land in `./Module2/optuna_artifacts/`:\n",
    "- `final_metrics.csv` (R¬≤, MAE, MAPE for train/val/test)\n",
    "- `scatter_train.png`, `scatter_test.png`\n",
    "- `trials_full.csv` (one row per Optuna trial with params + val MAE)\n",
    "- `best_track.csv` (MAE per trial + best‚Äêso‚Äêfar curve)\n",
    "- `mae_over_trials.png` (learning curve across trials)\n",
    "- `best_params.json`, `final_model.pkl`, `scaler_final.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "## üéõÔ∏è Knobs students can play with\n",
    "**Search budget**\n",
    "- `n_trials` in `study.optimize(...)` ‚Äì more trials ‚Üí better chances of finding good configs (but more time).\n",
    "- Or use time-boxing: `study.optimize(objective, timeout=180)`.\n",
    "\n",
    "**Model size & shape**\n",
    "- `n_layers` (1‚Äì3)  \n",
    "- `n_units_l{i}` (4‚Äì20, step 4) ‚Äì cap keeps it fast and forces compact networks.\n",
    "\n",
    "**Optimization & regularization**\n",
    "- `activation`: `\"relu\"` vs `\"tanh\"`\n",
    "- `alpha` (L2 weight decay): `1e-6` to `1e-2` (log scale)\n",
    "- `learning_rate_init`: `1e-4` to `1e-2` (log scale)\n",
    "- `batch_size`: `{64, 128, 256}`\n",
    "\n",
    "**Training dynamics**\n",
    "- `early_stopping=True` with `validation_fraction=0.1` and `n_iter_no_change=20`  \n",
    "  (This uses a **train-internal** holdout to stop early; Optuna still scores **external** validation for fairness.)\n",
    "- `max_iter` (e.g., 1000 while tuning, 2000 for final fit)\n",
    "\n",
    "**Objective**\n",
    "- We optimize **validation MAE**. Try swapping to `MAPE` or maximizing `R¬≤` (minimize `-R2`) to see trade-offs.\n",
    "\n",
    "**Reproducibility**\n",
    "- `RANDOM_STATE` controls both splitting and model seeds.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç How to read the outputs\n",
    "- **`mae_over_trials.png`**: Dots are each trial‚Äôs validation MAE; the line is the *best‚Äêso‚Äêfar*. If the line keeps dropping, more trials may help.\n",
    "- **`trials_full.csv`**: Explore which hyperparams correlate with lower MAE (e.g., smaller `learning_rate_init` + certain `alpha`).\n",
    "- **`final_metrics.csv`**: Check for overfitting. If train MAE ‚â™ test MAE, consider more regularization (`alpha` ‚Üë), smaller nets, or more patience with early stopping.\n",
    "- **Scatter plots**: Points tightly along `y=x` indicate better calibration; look for heteroscedasticity (fan shapes).\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ What Optuna does (high level)\n",
    "Optuna is an **automatic hyperparameter optimization** library. It frames tuning as:\n",
    "- A **study** (the whole experiment) composed of\n",
    "- multiple **trials** (one set of hyperparameters ‚Üí train ‚Üí score),\n",
    "- where a **sampler** proposes new hyperparameters each trial.\n",
    "\n",
    "By default we use **TPE (Tree-structured Parzen Estimator)**:\n",
    "1. It models two probability densities over the hyperparameter space:  \n",
    "   - one for **good** results (low MAE) and one for **not-so-good**.\n",
    "2. It then **samples** new hyperparameters where the ratio *p(good)/p(bad)* is high‚Äîbalancing **exploration** (try new areas) and **exploitation** (refine promising zones).\n",
    "3. Over trials, this Bayesian-inspired process **learns where better configs live**, usually beating naive grid/random searches for the same budget.\n",
    "\n",
    "**Key terms**\n",
    "- **Study**: the whole optimization run.\n",
    "- **Trial**: one attempt (train + evaluate with a specific param set).\n",
    "- **Params**: the hyperparameters suggested for a trial.\n",
    "- **Value**: the objective score returned (here: validation **MAE**).\n",
    "- **Sampler**: strategy for proposing params (TPE is the default workhorse).\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Extensions (great mini-experiments)\n",
    "- **Pruning**: stop bad trials early to save time (`optuna.integration` pruners).\n",
    "- **Cross-validation objective**: average MAE across folds instead of a single val split.\n",
    "- **Categorical search tweaks**: add/exclude activations, change unit ranges, try `batch_size=32` for stability.\n",
    "- **Logging & dashboards**: `optuna-dashboard` for interactive trial exploration.\n",
    "\n",
    "Have fun! Try small changes, run ~10‚Äì25 trials, and compare the artifacts you generate between runs. This is exactly how we iterate in real ML workflows. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:53:52,315] A new study created in memory with name: no-name-2a7ab0d7-f305-4edf-a1a3-5f345cc5c691\n",
      "  0%|          | 0/25 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:04,146] Trial 0 finished with value: 0.36647443102993993 and parameters: {'n_layers': 2, 'n_units_l1': 20, 'n_units_l2': 16, 'activation': 'relu', 'alpha': 4.207053950287936e-06, 'learning_rate_init': 0.00013066739238053285, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:   8%|‚ñä         | 2/25 [00:23<04:24, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:15,392] Trial 1 finished with value: 0.39011007294976646 and parameters: {'n_layers': 1, 'n_units_l1': 20, 'activation': 'relu', 'alpha': 5.337032762603957e-06, 'learning_rate_init': 0.00023270677083837802, 'batch_size': 128}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  12%|‚ñà‚ñè        | 3/25 [00:30<03:28,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:22,446] Trial 2 finished with value: 0.392796156175982 and parameters: {'n_layers': 1, 'n_units_l1': 16, 'activation': 'tanh', 'alpha': 2.9204338471814107e-05, 'learning_rate_init': 0.000816845589476017, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  16%|‚ñà‚ñå        | 4/25 [00:33<02:30,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:26,094] Trial 3 finished with value: 0.39218412450937495 and parameters: {'n_layers': 2, 'n_units_l1': 4, 'n_units_l2': 16, 'activation': 'relu', 'alpha': 0.006245139574743076, 'learning_rate_init': 0.00853618986286683, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  20%|‚ñà‚ñà        | 5/25 [00:37<02:00,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:30,058] Trial 4 finished with value: 0.37872750198541627 and parameters: {'n_layers': 3, 'n_units_l1': 12, 'n_units_l2': 4, 'n_units_l3': 12, 'activation': 'tanh', 'alpha': 1.0842262717330169e-05, 'learning_rate_init': 0.0021137059440645744, 'batch_size': 256}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:42<01:48,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:35,125] Trial 5 finished with value: 0.3888342345218851 and parameters: {'n_layers': 1, 'n_units_l1': 20, 'activation': 'tanh', 'alpha': 0.003795853142670641, 'learning_rate_init': 0.0015696396388661157, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:47<01:36,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:39,824] Trial 6 finished with value: 0.4150107493437893 and parameters: {'n_layers': 1, 'n_units_l1': 8, 'activation': 'relu', 'alpha': 0.0020651425578959264, 'learning_rate_init': 0.0005170191786366995, 'batch_size': 128}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:51<01:22,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:43,623] Trial 7 finished with value: 0.38441589726398406 and parameters: {'n_layers': 3, 'n_units_l1': 4, 'n_units_l2': 20, 'n_units_l3': 16, 'activation': 'relu', 'alpha': 0.0018274508859816032, 'learning_rate_init': 0.002592475660475161, 'batch_size': 128}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:54<01:11,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:47,177] Trial 8 finished with value: 0.4113002413312427 and parameters: {'n_layers': 2, 'n_units_l1': 4, 'n_units_l2': 20, 'activation': 'relu', 'alpha': 1.7956984225677624e-06, 'learning_rate_init': 0.0004187594718900631, 'batch_size': 128}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [01:06<01:41,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:54:59,206] Trial 9 finished with value: 0.37012690657257485 and parameters: {'n_layers': 3, 'n_units_l1': 12, 'n_units_l2': 4, 'n_units_l3': 16, 'activation': 'relu', 'alpha': 0.0012130221181165164, 'learning_rate_init': 0.0009718319944817398, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [01:32<02:55, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:24,722] Trial 10 finished with value: 0.3886756978446689 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'tanh', 'alpha': 0.00018300053640667708, 'learning_rate_init': 0.00011952270129143879, 'batch_size': 256}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.366474:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [01:44<02:39, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:36,306] Trial 11 finished with value: 0.41123521024337245 and parameters: {'n_layers': 3, 'n_units_l1': 12, 'n_units_l2': 4, 'n_units_l3': 4, 'activation': 'relu', 'alpha': 0.00028592111831985886, 'learning_rate_init': 0.0001317923269837779, 'batch_size': 64}. Best is trial 0 with value: 0.36647443102993993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [01:47<01:54,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:39,709] Trial 12 finished with value: 0.36051466828445433 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'relu', 'alpha': 0.0005197473211490454, 'learning_rate_init': 0.006665510953435556, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [01:50<01:23,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:42,893] Trial 13 finished with value: 0.3659967761149731 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'relu', 'alpha': 5.1580948836723734e-05, 'learning_rate_init': 0.009818226878189102, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [01:53<01:01,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:45,622] Trial 14 finished with value: 0.37864407980111736 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'relu', 'alpha': 5.2931921597924574e-05, 'learning_rate_init': 0.009886061418374873, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [01:57<00:49,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:49,574] Trial 15 finished with value: 0.36255921639276106 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'relu', 'alpha': 0.0004971782474948573, 'learning_rate_init': 0.005069521238203797, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [01:59<00:34,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:51,337] Trial 16 finished with value: 0.38364577664347194 and parameters: {'n_layers': 2, 'n_units_l1': 8, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.0005532709028590391, 'learning_rate_init': 0.00425627455524194, 'batch_size': 256}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [02:03<00:30,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:55,474] Trial 17 finished with value: 0.3646730703778574 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.000666431028775116, 'learning_rate_init': 0.004570102541959654, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [02:07<00:26,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:55:59,975] Trial 18 finished with value: 0.3874914420022282 and parameters: {'n_layers': 1, 'n_units_l1': 8, 'activation': 'tanh', 'alpha': 0.00014508608704143724, 'learning_rate_init': 0.004425557038568155, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [02:08<00:16,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:00,987] Trial 19 finished with value: 0.3792449297877108 and parameters: {'n_layers': 3, 'n_units_l1': 12, 'n_units_l2': 16, 'n_units_l3': 4, 'activation': 'relu', 'alpha': 0.009666555694984076, 'learning_rate_init': 0.005884303830089448, 'batch_size': 256}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [02:12<00:14,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:05,024] Trial 20 finished with value: 0.36453739268652213 and parameters: {'n_layers': 2, 'n_units_l1': 20, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.00036812112820042684, 'learning_rate_init': 0.00274149616533467, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [02:18<00:12,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:10,723] Trial 21 finished with value: 0.36784907888886864 and parameters: {'n_layers': 2, 'n_units_l1': 20, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.00041248303237075067, 'learning_rate_init': 0.00280964826862046, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [02:22<00:08,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:15,003] Trial 22 finished with value: 0.3738951743726374 and parameters: {'n_layers': 2, 'n_units_l1': 20, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.000946360773587218, 'learning_rate_init': 0.001587358013351102, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.360515:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [02:26<00:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:19,123] Trial 23 finished with value: 0.37212259529477637 and parameters: {'n_layers': 2, 'n_units_l1': 16, 'n_units_l2': 12, 'activation': 'relu', 'alpha': 7.954826327346708e-05, 'learning_rate_init': 0.00557551331170524, 'batch_size': 64}. Best is trial 12 with value: 0.36051466828445433.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.358643: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [02:33<00:00,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 14:56:26,021] Trial 24 finished with value: 0.35864318916592725 and parameters: {'n_layers': 2, 'n_units_l1': 20, 'n_units_l2': 8, 'activation': 'relu', 'alpha': 0.0003032566999511661, 'learning_rate_init': 0.0031586493225653225, 'batch_size': 64}. Best is trial 24 with value: 0.35864318916592725.\n",
      "Final metrics:\n",
      " split     R2    MAE   MAPE\n",
      "train 0.8011 0.3516 0.1933\n",
      "  val 0.7903 0.3517 0.1986\n",
      " test 0.7843 0.3617 0.2026\n",
      "\n",
      "Artifacts saved to: c:\\Users\\dww05002\\Desktop\\OPIM5512\\Module2\\optuna_artifacts\n"
     ]
    }
   ],
   "source": [
    "# ONE-CELL Optuna workflow for small MLPRegressor (‚â§20 units/layer, early stopping)\n",
    "# Artifacts saved to ./Module2/optuna_artifacts (folder is overwritten each run)\n",
    "\n",
    "# --- Imports & setup ---\n",
    "import os, shutil, json, pickle, datetime as dt, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# If Optuna isn't installed in your env, uncomment:\n",
    "# %pip install optuna\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "RESULTS_DIR = \"./optuna_artifacts\"\n",
    "\n",
    "# --- Recreate results directory ---\n",
    "if os.path.exists(RESULTS_DIR):\n",
    "    shutil.rmtree(RESULTS_DIR)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "with open(os.path.join(RESULTS_DIR, \"run_info.json\"), \"w\") as f:\n",
    "    json.dump({\"run_tag\": dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}, f, indent=2)\n",
    "\n",
    "# --- Load & split data (80/10/10) ---\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.frame.drop(columns=[\"MedHouseVal\"])\n",
    "y = data.frame[\"MedHouseVal\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# --- Scale with train-only stats ---\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# --- Optuna objective (minimize external VAL MAE); small nets + early stopping ---\n",
    "def objective(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    hidden_sizes = tuple(trial.suggest_int(f\"n_units_l{i+1}\", 4, 20, step=4) for i in range(n_layers))\n",
    "    params = {\n",
    "        \"hidden_layer_sizes\": hidden_sizes,\n",
    "        \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        \"solver\": \"adam\",\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1e-2, log=True),\n",
    "        \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-2, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256]),\n",
    "        \"max_iter\": 1000,\n",
    "        \"early_stopping\": True,      # internal split on TRAIN only\n",
    "        \"validation_fraction\": 0.1,\n",
    "        \"n_iter_no_change\": 20,\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"shuffle\": True,\n",
    "    }\n",
    "    model = MLPRegressor(**params).fit(X_train_s, y_train)\n",
    "    y_val_pred = model.predict(X_val_s)\n",
    "    return mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "# --- Callback to log CSVs/plot after every trial ---\n",
    "def log_progress_callback(study, trial):\n",
    "    df = study.trials_dataframe(attrs=(\"number\",\"value\",\"state\",\"datetime_start\",\"datetime_complete\"))\n",
    "    params_df = pd.DataFrame([t.params for t in study.trials])\n",
    "    if len(params_df):\n",
    "        df = pd.concat([df.reset_index(drop=True), params_df.reset_index(drop=True)], axis=1)\n",
    "    df.to_csv(os.path.join(RESULTS_DIR, \"trials_full.csv\"), index=False)\n",
    "\n",
    "    vals = df[\"value\"].astype(float).values\n",
    "    best_so_far = np.minimum.accumulate(vals)\n",
    "    pd.DataFrame({\"trial\": np.arange(len(vals)), \"val_mae\": vals, \"best_mae\": best_so_far}) \\\n",
    "      .to_csv(os.path.join(RESULTS_DIR, \"best_track.csv\"), index=False)\n",
    "\n",
    "    plt.figure(figsize=(6.5,4))\n",
    "    plt.plot(np.arange(len(vals)), vals, marker=\"o\", linewidth=1)\n",
    "    plt.plot(np.arange(len(vals)), best_so_far, linewidth=2)\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"Validation MAE\")\n",
    "    plt.title(\"Optuna: MAE per trial (line = best so far)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, \"mae_over_trials.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# --- Run study (calm search) ---\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=25, callbacks=[log_progress_callback], show_progress_bar=True)\n",
    "\n",
    "# Save best params\n",
    "with open(os.path.join(RESULTS_DIR, \"best_params.json\"), \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n",
    "\n",
    "# --- Retrain best model on TRAIN+VAL; evaluate on TEST; save metrics/plots/model ---\n",
    "best = study.best_params\n",
    "hidden_sizes = tuple(best[f\"n_units_l{i+1}\"] for i in range(best[\"n_layers\"]))\n",
    "final_params = {\n",
    "    \"hidden_layer_sizes\": hidden_sizes,\n",
    "    \"activation\": best[\"activation\"],\n",
    "    \"solver\": \"adam\",\n",
    "    \"alpha\": best[\"alpha\"],\n",
    "    \"learning_rate_init\": best[\"learning_rate_init\"],\n",
    "    \"batch_size\": best[\"batch_size\"],\n",
    "    \"max_iter\": 2000,\n",
    "    \"early_stopping\": True,\n",
    "    \"validation_fraction\": 0.1,\n",
    "    \"n_iter_no_change\": 25,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "\n",
    "# Refit scaler on TRAIN+VAL for the final model\n",
    "scaler_final = StandardScaler().fit(np.vstack([X_train, X_val]))\n",
    "X_trval_s = scaler_final.transform(np.vstack([X_train, X_val]))\n",
    "y_trval   = np.concatenate([y_train.values, y_val.values])\n",
    "X_train_sf = scaler_final.transform(X_train)\n",
    "X_val_sf   = scaler_final.transform(X_val)\n",
    "X_test_sf  = scaler_final.transform(X_test)\n",
    "\n",
    "final_model = MLPRegressor(**final_params).fit(X_trval_s, y_trval)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# Evaluate and save metrics\n",
    "rows = []\n",
    "for name, (Xsplit, ytrue) in {\n",
    "    \"train\": (X_train_sf, y_train.values),\n",
    "    \"val\":   (X_val_sf,   y_val.values),\n",
    "    \"test\":  (X_test_sf,  y_test.values),\n",
    "}.items():\n",
    "    ypred = final_model.predict(Xsplit)\n",
    "    rows.append({\"split\": name, **metrics(ytrue, ypred)})\n",
    "metrics_df = pd.DataFrame(rows).round(4)\n",
    "metrics_df.to_csv(os.path.join(RESULTS_DIR, \"final_metrics.csv\"), index=False)\n",
    "print(\"Final metrics:\\n\", metrics_df.to_string(index=False))\n",
    "\n",
    "# Scatterplot helper\n",
    "def scatter_with_reference(y_true, y_pred, title, outpath):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
    "    lo = min(np.min(y_true), np.min(y_pred))\n",
    "    hi = max(np.max(y_true), np.max(y_pred))\n",
    "    plt.plot([lo, hi], [lo, hi], linewidth=1)\n",
    "    plt.xlabel(\"Actual MedHouseVal\")\n",
    "    plt.ylabel(\"Predicted MedHouseVal\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Save train & test scatterplots\n",
    "scatter_with_reference(y_train.values, final_model.predict(X_train_sf),\n",
    "                       \"Predicted vs Actual ‚Äî Train\", os.path.join(RESULTS_DIR, \"scatter_train.png\"))\n",
    "scatter_with_reference(y_test.values, final_model.predict(X_test_sf),\n",
    "                       \"Predicted vs Actual ‚Äî Test\",  os.path.join(RESULTS_DIR, \"scatter_test.png\"))\n",
    "\n",
    "# Persist model & scaler\n",
    "with open(os.path.join(RESULTS_DIR, \"final_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(final_model, f)\n",
    "with open(os.path.join(RESULTS_DIR, \"scaler_final.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_final, f)\n",
    "\n",
    "print(f\"\\nArtifacts saved to: {os.path.abspath(RESULTS_DIR)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
