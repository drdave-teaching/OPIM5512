{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"General Modeling Framework_Advanced.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPLj9pqcV1xj6dLh4YpCmwC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zehws9Rhsk2m"},"source":["# General Modeling Framework: Advanced\n","**OPIM 5512: Data Science Using Python - University of Connecticut**\n","\n","--------------------------------------\n","\n","This is a bare-bones script to get you up and running. For a given dataset, you should be able to code relevant content in the cells below. \n","\n","THIS is how you need to be thinking when you approach a problem"]},{"cell_type":"markdown","metadata":{"id":"xhEQ0UwesvAB"},"source":["# Import Modules\n","Import modules, mount Drive, read in the data, check data types and missing values. You may also do some light EDA prior to modeling.\n"]},{"cell_type":"code","metadata":{"id":"QqeDxYgSs2OG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coSlPqD0-2GY"},"source":["# Feature Engineering\n","Polynomial features, interaction terms, dummy variables."]},{"cell_type":"code","metadata":{"id":"1keJLChp-7kr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hRSBaBBhs3og"},"source":["# Data splitting\n","Subset your data into X features and Y target variable for modeling. Convert X and Y to numpy arrays. Then use train_test_split for data splitting (80/20 is very common); don't forget random seed and shuffle."]},{"cell_type":"code","metadata":{"id":"K3TFxlOdt1dH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E5vFxGifuPzF"},"source":["# Min/Max Scaling\n","This will ensure all of your X data is between 0 (min) and 1 (max). You will use fit_transform() on the train data first, then fit on the test data. If you don't do this step after splitting, you will have data leakage. \n","\n","Only scale the X data, not the Y data! Be careful of the difference between fit_transform() and transform()."]},{"cell_type":"code","metadata":{"id":"D9KyPXdiujPv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_gfeorkns0k"},"source":["# Feature Engineering\r\n","Polynomial features, PCA, etc."]},{"cell_type":"code","metadata":{"id":"BJfQN2yWnwmB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SjiD7wWVtT5X"},"source":["# Fit The Model\n","Fit the model and make new variables to save your train and test predictions. Make sure you are using the appropriate regression or classification model."]},{"cell_type":"code","metadata":{"id":"g5_x7INZt02l"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vRsCK_5Jtb0Z"},"source":["# Evaluate the Model\n","Look at the appropriate error metrics depending on the problem you are solving. \n","\n","For a regression problem, look at the R2, MAE and MSE; then make a scatterplot of actual vs. predicted values with nice labels and titles.\n","\n","For a classification problem, create the classification report (gives a confusion matrix and useful metrics in one line of code)."]},{"cell_type":"code","metadata":{"id":"eZpoSiYQ-yaF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-k4IqLSO-lOW"},"source":["# Feature Importance\n","Implement feature importance with 10x repeated (to make sure it's not a fluke pattern)."]},{"cell_type":"code","metadata":{"id":"TO3jMvij-xsV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttv4Dc7p-nJN"},"source":["# ICE and Partial Dependence Plots\n","How does the model treat the data you fed it with?"]},{"cell_type":"code","metadata":{"id":"MSydlALQskCS"},"source":[""],"execution_count":null,"outputs":[]}]}